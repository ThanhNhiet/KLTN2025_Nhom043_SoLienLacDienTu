// services/faq.service.js
const { FaqSection } = require("../databases/mongodb/schemas/FaqSection");
const { openai } = require("../config/openIA.conf");

// ================== CONFIG ==================
const OUT_OF_SCOPE_MESSAGE =
  "C√¢u h·ªèi n√†y n·∫±m ngo√†i ph·∫°m vi tr·∫£ l·ªùi c·ªßa t√¥i, h√£y li√™n h·ªá Qu·∫£n tr·ªã vi√™n h·ªá th·ªëng - SƒêT 0834258511 ƒë·ªÉ c√≥ ƒë∆∞·ª£c c√¢u tr·∫£ l·ªùi ch√≠nh x√°c nh·∫•t.";

const MIN_SCORE = 0.25;          // ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng t·ªëi thi·ªÉu (0.2‚Äì0.3 l√† h·ª£p l√Ω)
const DEFAULT_MODEL = "gpt-4.1-mini";

// ================== COMMON UTILS ==================
async function ensureConnection() {
  if (!FaqSection) {
    throw new Error("FaqSection schema is not initialized.");
  }
  try {
    await FaqSection.collection.estimatedDocumentCount();
  } catch (err) {
    throw new Error(`Database connection failed: ${err.message}`);
  }
}

// L·∫•y danh s√°ch section cho UI dropdown
async function listSections() {
  await ensureConnection();
  const docs = await FaqSection.find({}, { section: 1 }).sort({ section: 1 }).lean();
  return docs.map((d) => d.section);
}

const norm = (s) =>
  (s || "")
    .toLowerCase()
    .normalize("NFD")
    .replace(/[\u0300-\u036f]/g, "") // b·ªè d·∫•u ti·∫øng Vi·ªát
    .replace(/\s+/g, " ")
    .trim();

const toTokens = (s) => norm(s).split(/\s+/).filter(Boolean);

const jaccard = (A, B) => {
  const a = new Set(A),
    b = new Set(B);
  const inter = [...a].filter((x) => b.has(x)).length;
  const uni = new Set([...a, ...b]).size;
  return uni ? inter / uni : 0;
};

// ================== MATCH HELPERS ==================
// üîé T√¨m top-k trong 1 document, ch·ªâ d·ª±a tr√™n C√ÇU H·ªéI (qa.q)
function findBestMatchesInDoc(question, doc, k = 6) {
  const qTok = toTokens(question);
  const exact = [];
  const scored = [];

  for (const qa of doc.QuestionsAndAnswers || []) {
    const qTokens = toTokens(qa.q);

    // N·∫øu gi·ªëng 100% sau khi b·ªè d·∫•u ‚Üí coi l√† exact
    if (norm(qa.q) === norm(question)) {
      exact.push({ section: doc.section, ...qa, score: 1 });
    } else {
      const score = jaccard(qTok, qTokens);
      scored.push({ section: doc.section, ...qa, score });
    }
  }

  if (exact.length) return exact.slice(0, k);
  return scored.sort((a, b) => b.score - a.score).slice(0, k);
}

// üîé T√¨m top-k tr√™n nhi·ªÅu document
function findBestMatchesAcrossDocs(question, docs, k = 6) {
  const qTok = toTokens(question);
  const exact = [];
  const scored = [];

  for (const d of docs) {
    for (const qa of d.QuestionsAndAnswers || []) {
      const qTokens = toTokens(qa.q);

      if (norm(qa.q) === norm(question)) {
        exact.push({ section: d.section, ...qa, score: 1 });
      } else {
        const score = jaccard(qTok, qTokens);
        scored.push({ section: d.section, ...qa, score });
      }
    }
  }

  if (exact.length) return exact.slice(0, k);
  return scored.sort((a, b) => b.score - a.score).slice(0, k);
}

// ================== INTENT DETECTION ==================
function safeParseIntent(text) {
  if (!text) return null;
  // lo·∫°i b·ªè code fence n·∫øu c√≥
  const cleaned = text.replace(/```json|```/g, "").trim();
  try {
    const obj = JSON.parse(cleaned);
    if (obj && typeof obj.intent === "string") {
      return obj.intent;
    }
  } catch (e) {
    // ignore
  }
  return null;
}

/**
 * detectIntent: tr·∫£ v·ªÅ 'faq' | 'small_talk' | 'other'
 */
async function detectIntent(question) {
  const r = await openai.chat.completions.create({
    model: DEFAULT_MODEL,
    temperature: 0,
    messages: [
      {
        role: "system",
        content:
          "B·∫°n l√† b·ªô ph√¢n lo·∫°i intent. " +
          "H√£y ph√¢n lo·∫°i c√¢u c·ªßa ng∆∞·ªùi d√πng v√†o ƒë√∫ng 1 trong 3 nh√£n: " +
          " - 'faq': c√¢u h·ªèi v·ªÅ quy ƒë·ªãnh, h·ªçc v·ª•, ƒëi·ªÉm, l·ªãch h·ªçc, l·ªãch thi, th·ªß t·ª•c h√†nh ch√≠nh... " +
          " - 'small_talk': ch√†o h·ªèi, c·∫£m ∆°n, xin l·ªói, khen, than v√£n, n√≥i chuy·ªán x√£ giao... " +
          " - 'other': c√°c c√¢u c√≤n l·∫°i (vd: th∆°, chuy·ªán c∆∞·ªùi, l·∫≠p tr√¨nh,... kh√¥ng li√™n quan h·ªçc v·ª•).\n" +
          "Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng JSON d·∫°ng: " +
          '{"intent":"faq"} ho·∫∑c {"intent":"small_talk"} ho·∫∑c {"intent":"other"}.'
      },
      {
        role: "user",
        content: question
      }
    ]
  });

  const text = r.choices?.[0]?.message?.content?.trim() || "";
  const intent = safeParseIntent(text);
  // N·∫øu parse fail ‚Üí m·∫∑c ƒë·ªãnh 'faq' ƒë·ªÉ an to√†n (kh√¥ng cho AI b·ªãa quy ƒë·ªãnh)
  return intent || "faq";
}

// ================== AI MAIN FUNCTION ==================
async function createChatMessageAI(
  section,
  question,
  { model = DEFAULT_MODEL, maxContextChars = 12000, maxTokens = 300 } = {}
) {
  if (!question) throw new Error("question is required");

  // --------- B∆Ø·ªöC 1: AI T·ª∞ NH·∫¨N DI·ªÜN INTENT ----------
  const intent = await detectIntent(question);

  // ===== SMALL TALK: ƒë·ªÉ OpenAI tr·∫£ l·ªùi linh ƒë·ªông, kh√¥ng d√πng DB =====
  if (intent === "small_talk") {
    const r = await openai.chat.completions.create({
      model,
      temperature: 0.7,
      // max_tokens: maxTokens,
      messages: [
        {
          role: "system",
          content:
            "B·∫°n l√† tr·ª£ l√Ω h·ªçc v·ª• th√¢n thi·ªán. ƒê√¢y l√† c√¢u small talk (ch√†o h·ªèi, c·∫£m ∆°n...). " +
            "H√£y tr·∫£ l·ªùi t·ª± nhi√™n, ng·∫Øn g·ªçn, t√≠ch c·ª±c. " +
            "Kh√¥ng c·∫ßn tr√≠ch d·∫´n quy ƒë·ªãnh hay d·ªØ li·ªáu trong h·ªá th·ªëng."
        },
        {
          role: "user",
          content: question
        }
      ]
    });

    return {
      answer: r.choices?.[0]?.message?.content?.trim() || "Ch√†o b·∫°n üëã",
      section: null,
      matches: []
    };
  }

  // ===== OTHER: c√¢u h·ªèi ngo√†i h·ªçc v·ª• ‚Üí cho AI tr·∫£ l·ªùi t·ª± do, KH√îNG d√πng OUT_OF_SCOPE_MESSAGE =====
  if (intent === "other") {
    const r = await openai.chat.completions.create({
      model,
      temperature: 0.7,
      // max_tokens: maxTokens,
      messages: [
        {
          role: "system",
          content:
            "B·∫°n l√† tr·ª£ l√Ω th√¢n thi·ªán, tr·∫£ l·ªùi c√°c c√¢u h·ªèi chung (kh√¥ng li√™n quan t·ªõi h·ªçc v·ª•). " +
            "Kh√¥ng ƒë∆∞·ª£c t·ª± b·ªãa ra c√°c quy ƒë·ªãnh, ch√≠nh s√°ch c·ªßa nh√† tr∆∞·ªùng. " +
            "N·∫øu ng∆∞·ªùi d√πng b·∫•t ng·ªù h·ªèi v·ªÅ quy ƒë·ªãnh h·ªçc v·ª•, h√£y n√≥i h·ªç n√™n ƒë·∫∑t c√¢u h·ªèi ƒë√≥ trong m·ª•c H·ªèi ƒë√°p h·ªçc v·ª•."
        },
        {
          role: "user",
          content: question
        }
      ]
    });

    return {
      answer: r.choices?.[0]?.message?.content?.trim() || "M√¨nh ƒë√£ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n r·ªìi ƒë√≥ üòä",
      section: null,
      matches: []
    };
  }

  // T·ªöI ƒê√ÇY th√¨ ch·ªâ c√≤n 'faq' ‚Üí ƒëi qua pipeline FAQ
  await ensureConnection();

  // ===== TR∆Ø·ªúNG H·ª¢P 1: C√ì SECTION (ch·ªâ trong 1 m·ª•c) =====
  if (section) {
    let doc = await FaqSection.findOne({ section }).lean();
    if (!doc) {
      const all = await FaqSection.find({}, { section: 1, QuestionsAndAnswers: 1 }).lean();
      doc = all.find((d) => norm(d.section) === norm(section));
    }
    if (!doc) {
      // Kh√¥ng c√≥ m·ª•c n√†y trong DB -> out of scope lu√¥n (h·ªçc v·ª• nh∆∞ng kh√¥ng c√≥ d·ªØ li·ªáu)
      return { answer: OUT_OF_SCOPE_MESSAGE, section: null, matches: [] };
    }
    if (!doc.QuestionsAndAnswers?.length) {
      return { answer: OUT_OF_SCOPE_MESSAGE, section: doc.section, matches: [] };
    }

    // L·ªçc Q&A g·∫ßn nh·∫•t trong ch√≠nh section ƒë√≥
    const top = findBestMatchesInDoc(question, doc, 6);
    if (!top.length || (top[0].score ?? 0) < MIN_SCORE) {
      // C√¢u h·ªèi h·ªçc v·ª• nh∆∞ng kh√¥ng gi·ªëng Q&A n√†o ƒë·ªß m·ª©c tin c·∫≠y
      // ‚Üí KH√îNG G·ªåI AI t·ª± b·ªãa, tr·∫£ lu√¥n message custom
      return { answer: OUT_OF_SCOPE_MESSAGE, section: doc.section, matches: [] };
    }

    // Build context t·ª´ top-k thay v√¨ c·∫£ section
    let context = `M·ª§C: ${doc.section}\n\n`;
    top.forEach((t, i) => {
      context += `#${i + 1} H·ªéI: ${t.q}\nƒê√ÅP: ${t.a}\n\n`;
    });
    if (context.length > maxContextChars) {
      context = context.slice(0, maxContextChars) + "\n... (ƒë√£ r√∫t g·ªçn)\n";
    }

    const r = await openai.chat.completions.create({
      model,
      temperature: 0,
      // max_tokens: maxTokens,
      messages: [
        {
          role: "system",
          content:
            "B·∫°n l√† tr·ª£ l√Ω h·ªçc v·ª•. CH·ªà tr·∫£ l·ªùi d·ª±a tr√™n CONTEXT b√™n d∆∞·ªõi (c√°c quy ƒë·ªãnh ch√≠nh th·ª©c).\n" +
            "N·∫øu c√¢u h·ªèi kh√¥ng n·∫±m trong CONTEXT, h√£y tr·∫£ l·ªùi CH√çNH X√ÅC nh∆∞ sau (kh√¥ng th√™m b·ªõt):\n" +
            `"${OUT_OF_SCOPE_MESSAGE}"`
        },
        {
          role: "user",
          content:
            `CONTEXT (theo m·ª•c ƒë√£ ch·ªçn):\n${context}\n\n` +
            `C√ÇU H·ªéI: ${question}\n\n` +
            "Y√äU C·∫¶U: tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c; n·∫øu ƒë∆∞·ª£c, n√™u #n t∆∞∆°ng ·ª©ng."
        }
      ]
    });

    return {
      answer: r.choices?.[0]?.message?.content?.trim() || OUT_OF_SCOPE_MESSAGE,
      section: doc.section,
      matches: top.map((m, i) => ({
        rank: i + 1,
        q: m.q,
        score: Number(m.score.toFixed(3))
      }))
    };
  }

  // ===== TR∆Ø·ªúNG H·ª¢P 2: KH√îNG C√ì SECTION (t√¨m tr√™n to√†n b·ªô) =====
  const allDocs = await FaqSection.find(
    {},
    { section: 1, QuestionsAndAnswers: 1 }
  ).lean();

  if (!allDocs.length) {
    // H·ªçc v·ª• nh∆∞ng kh√¥ng c√≥ d·ªØ li·ªáu ‚Üí out of scope
    return { answer: OUT_OF_SCOPE_MESSAGE, section: null, matches: [] };
  }

  const top = findBestMatchesAcrossDocs(question, allDocs, 6);
  if (!top.length || (top[0].score ?? 0) < MIN_SCORE) {
    // H·ªçc v·ª• nh∆∞ng kh√¥ng match ƒë·ªß t·ªët ‚Üí out of scope
    return { answer: OUT_OF_SCOPE_MESSAGE, section: null, matches: [] };
  }

  let context = "";
  top.forEach((t, i) => {
    context += `#${i + 1} [${t.section}] H·ªéI: ${t.q}\nƒê√ÅP: ${t.a}\n\n`;
  });
  if (context.length > maxContextChars) {
    context = context.slice(0, maxContextChars) + "\n... (ƒë√£ r√∫t g·ªçn)\n";
  }

  const r = await openai.chat.completions.create({
    model,
    temperature: 0,
    // max_tokens: maxTokens,
    messages: [
      {
        role: "system",
        content:
          "B·∫°n l√† tr·ª£ l√Ω h·ªçc v·ª•. CH·ªà tr·∫£ l·ªùi d·ª±a tr√™n CONTEXT sau (bao g·ªìm nhi·ªÅu m·ª•c).\n" +
          "N·∫øu c√¢u h·ªèi kh√¥ng n·∫±m trong CONTEXT, h√£y tr·∫£ l·ªùi CH√çNH X√ÅC nh∆∞ sau (kh√¥ng th√™m b·ªõt):\n" +
          `"${OUT_OF_SCOPE_MESSAGE}"`
      },
      {
        role: "user",
        content:
          `CONTEXT (top k·∫øt qu·∫£ t·ª´ nhi·ªÅu m·ª•c):\n${context}\n\n` +
          `C√ÇU H·ªéI: ${question}\n` +
          "Y√äU C·∫¶U: tr·∫£ l·ªùi ng·∫Øn g·ªçn, n·∫øu c√≥ n√™u #n v√† [section]."
      }
    ]
  });

  const answer = r.choices?.[0]?.message?.content?.trim() || OUT_OF_SCOPE_MESSAGE;
  return {
    answer,
    section: null,
    matches: top.map((m, i) => ({
      rank: i + 1,
      section: m.section,
      q: m.q,
      score: Number(m.score.toFixed(3))
    }))
  };
}

module.exports = {
  listSections,
  createChatMessageAI
};
